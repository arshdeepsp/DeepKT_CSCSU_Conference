{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aDmPpicpKzG"
      },
      "source": [
        "# Deep Knowledge Tracing using Transformer model\n",
        "\n",
        "Dataset: Assistments 2017"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9dWWynLpWeg"
      },
      "source": [
        "# Data Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOcSYVLnTTkg"
      },
      "source": [
        "Import Dataset from Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-RKcKY1pdZw",
        "outputId": "73a3fcbb-0c5a-4d70-8d7d-e2ce5ef3b9cd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "assistments = pd.read_csv('/content/drive/MyDrive/DeepKT/assistments_2017.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E2M0FYsQLUm"
      },
      "source": [
        "**Assistments 2017**\n",
        "\n",
        "We will use mainly 2 columns from the dataframe: Skill and Correctness, the other two columns will be for aiding preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "UTLa7NWpQKwY",
        "outputId": "725b1831-9bd7-479b-d070-bdbcc5eaa97e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"assistments[['studentId', 'skill', 'correct', 'action_num']]\",\n  \"rows\": 15000,\n  \"fields\": [\n    {\n      \"column\": \"studentId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 104,\n        \"min\": 8,\n        \"max\": 337,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          8,\n          291,\n          283\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"skill\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 87,\n        \"samples\": [\n          \"congruence\",\n          \"properties-of-geometric-figures\",\n          \"venn-diagram\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"correct\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"action_num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80304,\n        \"min\": 9950,\n        \"max\": 269099,\n        \"num_unique_values\": 15000,\n        \"samples\": [\n          221034,\n          158659\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a4a42c0f-d148-493b-99a6-120e49ad6059\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>studentId</th>\n",
              "      <th>skill</th>\n",
              "      <th>correct</th>\n",
              "      <th>action_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>properties-of-geometric-figures</td>\n",
              "      <td>0</td>\n",
              "      <td>9950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>properties-of-geometric-figures</td>\n",
              "      <td>1</td>\n",
              "      <td>9951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>sum-of-interior-angles-more-than-3-sides</td>\n",
              "      <td>0</td>\n",
              "      <td>9952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>sum-of-interior-angles-more-than-3-sides</td>\n",
              "      <td>0</td>\n",
              "      <td>9953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>sum-of-interior-angles-more-than-3-sides</td>\n",
              "      <td>1</td>\n",
              "      <td>9954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14995</th>\n",
              "      <td>337</td>\n",
              "      <td>interpreting-numberline</td>\n",
              "      <td>1</td>\n",
              "      <td>269095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14996</th>\n",
              "      <td>337</td>\n",
              "      <td>interpreting-numberline</td>\n",
              "      <td>1</td>\n",
              "      <td>269096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14997</th>\n",
              "      <td>337</td>\n",
              "      <td>interpreting-numberline</td>\n",
              "      <td>0</td>\n",
              "      <td>269097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14998</th>\n",
              "      <td>337</td>\n",
              "      <td>inequality-solving</td>\n",
              "      <td>0</td>\n",
              "      <td>269098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14999</th>\n",
              "      <td>337</td>\n",
              "      <td>inequality-solving</td>\n",
              "      <td>0</td>\n",
              "      <td>269099</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15000 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4a42c0f-d148-493b-99a6-120e49ad6059')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a4a42c0f-d148-493b-99a6-120e49ad6059 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a4a42c0f-d148-493b-99a6-120e49ad6059');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-22c77080-c74e-41de-a7d2-04c88be7db04\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-22c77080-c74e-41de-a7d2-04c88be7db04')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-22c77080-c74e-41de-a7d2-04c88be7db04 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       studentId                                     skill  correct  \\\n",
              "0              8           properties-of-geometric-figures        0   \n",
              "1              8           properties-of-geometric-figures        1   \n",
              "2              8  sum-of-interior-angles-more-than-3-sides        0   \n",
              "3              8  sum-of-interior-angles-more-than-3-sides        0   \n",
              "4              8  sum-of-interior-angles-more-than-3-sides        1   \n",
              "...          ...                                       ...      ...   \n",
              "14995        337                   interpreting-numberline        1   \n",
              "14996        337                   interpreting-numberline        1   \n",
              "14997        337                   interpreting-numberline        0   \n",
              "14998        337                        inequality-solving        0   \n",
              "14999        337                        inequality-solving        0   \n",
              "\n",
              "       action_num  \n",
              "0            9950  \n",
              "1            9951  \n",
              "2            9952  \n",
              "3            9953  \n",
              "4            9954  \n",
              "...           ...  \n",
              "14995      269095  \n",
              "14996      269096  \n",
              "14997      269097  \n",
              "14998      269098  \n",
              "14999      269099  \n",
              "\n",
              "[15000 rows x 4 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "assistments[['studentId', 'skill', 'correct', 'action_num']].head(15000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2lEmy8jqRyw"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpaBZTmQqZCO",
        "outputId": "8ae99c39-4e5d-43df-bebf-9fcb524f6b51"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple, List, Dict, Any\n",
        "\n",
        "@dataclass\n",
        "class SequenceConfig:\n",
        "    seq_length: int\n",
        "    sliding_window_step: int = 1\n",
        "    max_students: int = 100\n",
        "\n",
        "class SequenceGenerator:\n",
        "    def __init__(self, config: SequenceConfig, skill_to_id: Dict):\n",
        "        self.config = config  # Configuring the parameters for preprocessing\n",
        "        self.skill_to_id = {}  # Mapping skills to unique IDs\n",
        "        self.num_skills = 0  # Will be set during data loading\n",
        "\n",
        "    def load_and_process(self, file) -> Tuple[pd.DataFrame, int]:\n",
        "        # Load and preprocess data from Dataset\n",
        "        data = file\n",
        "\n",
        "        self.num_skills = data['skill'].nunique()\n",
        "\n",
        "        # Sort by student and action number\n",
        "        data = data.sort_values(by=['studentId', 'action_num'])\n",
        "\n",
        "        # Select limited number of students if specified\n",
        "        selected_students = data['studentId'].unique()[:self.config.max_students]\n",
        "        data = data[data['studentId'].isin(selected_students)]\n",
        "\n",
        "        # Create skill mapping\n",
        "        self.skill_to_id = self.skill_map(data)\n",
        "\n",
        "        return data, self.num_skills\n",
        "\n",
        "    def skill_map(self, data: pd.DataFrame) -> Dict[str, int]:\n",
        "        skill_to_id = {}\n",
        "\n",
        "        for skill in data['skill'].unique():\n",
        "            skill_to_id[skill] = len(skill_to_id)\n",
        "\n",
        "        return skill_to_id\n",
        "\n",
        "    def encode_interaction(self, skill: int, correctness: int) -> List[int]:\n",
        "        \"\"\"\n",
        "        Encode skill and correctness using one-hot encoding\n",
        "        Returns a vector of length (num_skills * 2) where:\n",
        "        - First num_skills positions represent correct responses for each skill\n",
        "        - Last num_skills positions represent incorrect responses for each skill\n",
        "        \"\"\"\n",
        "        # Create a zero vector of length num_skills * 2\n",
        "        encoded = np.zeros(self.num_skills * 2, dtype=int)\n",
        "\n",
        "        # Set the appropriate position to 1\n",
        "        if correctness == 1:\n",
        "            # Correct response for this skill\n",
        "            encoded[skill] = 1\n",
        "        else:\n",
        "            # Incorrect response for this skill\n",
        "            encoded[skill + self.num_skills] = 1\n",
        "\n",
        "        return encoded.tolist()\n",
        "\n",
        "    def generate_label(self, skill: int, correctness: int) -> List[int]:\n",
        "        \"\"\"Create one-hot encoded label vector\"\"\"\n",
        "        # Create a zero vector of length num_skills\n",
        "        label = np.zeros(self.num_skills, dtype=int)\n",
        "\n",
        "        # Set the skill position to correctness value (0 or 1)\n",
        "        label[skill] = correctness\n",
        "\n",
        "        return label.tolist()\n",
        "\n",
        "    def prepare_student_sequences(self, student_data: pd.DataFrame) -> Tuple[List[List[List[int]]], List[List[int]]]:\n",
        "        \"\"\"Prepare sequences for each student\"\"\"\n",
        "        sequences = []\n",
        "        labels = []\n",
        "\n",
        "        if len(student_data) < self.config.seq_length + 1:  # +1 for the next interaction\n",
        "            return sequences, labels\n",
        "\n",
        "        for i in range(0, len(student_data) - self.config.seq_length, self.config.sliding_window_step):\n",
        "            if i + self.config.seq_length >= len(student_data):\n",
        "                break\n",
        "\n",
        "            # Get window of interactions\n",
        "            window = student_data.iloc[i:i + self.config.seq_length]\n",
        "\n",
        "            # Get the next interaction after the sequence\n",
        "            next_interaction = student_data.iloc[i + self.config.seq_length]\n",
        "            next_skill_id = self.skill_to_id[next_interaction['skill']]\n",
        "            next_correctness = next_interaction['correct']\n",
        "\n",
        "            # Encode the sequence\n",
        "            encoded_sequence = [\n",
        "                self.encode_interaction(\n",
        "                    self.skill_to_id[row['skill']],\n",
        "                    row['correct']\n",
        "                ) for _, row in window.iterrows()\n",
        "            ]\n",
        "\n",
        "            # Generate label for the next interaction\n",
        "            label = self.generate_label(next_skill_id, next_correctness)\n",
        "\n",
        "            sequences.append(encoded_sequence)\n",
        "            labels.append(label)\n",
        "\n",
        "        return sequences, labels\n",
        "\n",
        "    def prepare_sequences(self, df: pd.DataFrame) -> Tuple[List[List[List[int]]], List[List[int]]]:\n",
        "        \"\"\"Prepare sequences for all students\"\"\"\n",
        "        all_sequences = []\n",
        "        all_labels = []\n",
        "\n",
        "        for student_id in df['studentId'].unique():\n",
        "            student_data = df[df['studentId'] == student_id]\n",
        "\n",
        "            student_seq, student_lab = self.prepare_student_sequences(student_data)\n",
        "\n",
        "            all_sequences.extend(student_seq)\n",
        "            all_labels.extend(student_lab)\n",
        "\n",
        "        return all_sequences, all_labels\n",
        "\n",
        "\n",
        "config = SequenceConfig(seq_length=10, sliding_window_step=5, max_students=200)\n",
        "generator = SequenceGenerator(config, {})\n",
        "df, num_skills = generator.load_and_process(assistments)\n",
        "seq, lab = generator.prepare_sequences(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_DGB88HlQXu"
      },
      "source": [
        "# **Save and Load Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyuVFtcflVqO",
        "outputId": "4f8b3267-cb44-43d7-e1d7-f0e96d63a740"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import json\n",
        "import os\n",
        "\n",
        "def save_preprocessed_data(sequences, labels, skill_to_id, config, save_dir='/content/drive/MyDrive/DeepKT/preprocessed_data'):\n",
        "    \"\"\"Save preprocessed data to Google Drive\"\"\"\n",
        "    # Mount Google Drive if not already mounted\n",
        "    if not os.path.exists('/content/drive'):\n",
        "        drive.mount('/content/drive')\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # Save sequences and labels\n",
        "    np.save(os.path.join(save_dir, 'sequences_10_2.npy'), np.array(sequences))\n",
        "    np.save(os.path.join(save_dir, 'labels_10_2.npy'), np.array(labels))\n",
        "\n",
        "    # Save skill mapping and configuration\n",
        "    metadata = {\n",
        "        'skill_to_id': skill_to_id,\n",
        "        'config': {\n",
        "            'seq_length': config.seq_length,\n",
        "            'sliding_window_step': config.sliding_window_step,\n",
        "            'num_students': config.max_students\n",
        "        },\n",
        "        'dataset_stats': {\n",
        "            'num_sequences': len(sequences),\n",
        "            'sequence_length': len(sequences[0]) if sequences else 0,\n",
        "            'num_skills': len(skill_to_id)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(save_dir, 'metadata_10_2.json'), 'w') as f:\n",
        "        json.dump(metadata, f, indent=2)\n",
        "\n",
        "    print(f\"Data saved successfully to {save_dir}\")\n",
        "    print(\"Files saved:\")\n",
        "    print(f\"- sequences_10_2.npy: {os.path.getsize(os.path.join(save_dir, 'sequences_10_2.npy'))/1024/1024:.2f} MB\")\n",
        "    print(f\"- labels_10_2.npy: {os.path.getsize(os.path.join(save_dir, 'labels_10_2.npy'))/1024/1024:.2f} MB\")\n",
        "    print(f\"- metadata_10_2.json: {os.path.getsize(os.path.join(save_dir, 'metadata_10_2.json'))/1024:.2f} KB\")\n",
        "\n",
        "# # Save Preprocessed Data:\n",
        "save_preprocessed_data(seq, lab, gen.skill_to_id, gen.config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDzwvj9jkPsW"
      },
      "source": [
        "# **In case already preprocessed, load initial packages and start here**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOP9YxcUi22B",
        "outputId": "91107acb-6cb6-4e68-d622-ed53d6566d17"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import json\n",
        "import os\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "\n",
        "def load_preprocessed_data(load_dir='/content/drive/MyDrive/DeepKT/preprocessed_data'):\n",
        "    \"\"\"Load preprocessed data from Google Drive\"\"\"\n",
        "    if not os.path.exists('/content/drive'):\n",
        "        drive.mount('/content/drive')\n",
        "\n",
        "    # Load sequences and labels\n",
        "    sequences = np.load(os.path.join(load_dir, 'sequences_10_2.npy'))\n",
        "    labels = np.load(os.path.join(load_dir, 'labels_10_2.npy'))\n",
        "\n",
        "    # Load metadata\n",
        "    with open(os.path.join(load_dir, 'metadata_10_2.json'), 'r') as f:\n",
        "        metadata = json.load(f)\n",
        "\n",
        "    print(\"Data loaded successfully\")\n",
        "    print(f\"Loaded {metadata['dataset_stats']['num_sequences']} sequences\")\n",
        "    print(f\"Sequence length: {metadata['dataset_stats']['sequence_length']}\")\n",
        "    print(f\"Number of skills: {metadata['dataset_stats']['num_skills']}\")\n",
        "\n",
        "    return sequences, labels, metadata\n",
        "\n",
        "# Load in preprocessed data\n",
        "sequences, labels, metadata = load_preprocessed_data()\n",
        "\n",
        "print(sequences[:50])\n",
        "print(labels[:50])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jHKa8nWKRm-"
      },
      "source": [
        "# Data Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFtiyMCZKRWE",
        "outputId": "15e65721-5e27-4021-9621-2cbca5affe63"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def prepare_data(sequences, labels, batch_size = 64, train_ratio = 0.7, val_ratio = 0.15):\n",
        "  sequences = sequences.astype(np.int32)\n",
        "  labels = labels.astype(np.float32)\n",
        "\n",
        "  train_sequences, temp_sequences, train_labels, temp_labels = train_test_split(sequences, labels, train_size=train_ratio, random_state=42)\n",
        "\n",
        "  val_ratio_adjusted = val_ratio / (1 - train_ratio)\n",
        "\n",
        "  val_sequences, test_sequences, val_labels, test_labels = train_test_split(temp_sequences, temp_labels, train_size=val_ratio_adjusted, random_state=42)\n",
        "\n",
        "  def create_dataset(sequences, labels, batch_size, training=False):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((sequences, labels))\n",
        "\n",
        "    if training:\n",
        "      dataset = dataset.shuffle(len(sequences)) # Shuffle tensors\n",
        "\n",
        "    dataset = dataset.batch(batch_size)\n",
        "\n",
        "    if training:\n",
        "      dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE) # Prefetch for optimum training\n",
        "\n",
        "    return dataset\n",
        "\n",
        "  train_dataset = create_dataset(train_sequences, train_labels, batch_size)\n",
        "  val_dataset = create_dataset(val_sequences, val_labels, batch_size)\n",
        "  test_dataset = create_dataset(test_sequences, test_labels, batch_size)\n",
        "\n",
        "  return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = prepare_data(sequences, labels)\n",
        "\n",
        "def inspect_dataset(dataset, name=\"Dataset\"):\n",
        "    \"\"\"Helper function to inspect the prepared datasets\"\"\"\n",
        "    for sequences, labels in dataset.take(1):\n",
        "        print(f\"\\n{name} inspection:\")\n",
        "        print(f\"Sequences shape: {sequences.shape}\")\n",
        "        print(f\"Labels shape: {labels.shape}\")\n",
        "        print(f\"Sequences dtype: {sequences.dtype}\")\n",
        "        print(f\"Labels dtype: {labels.dtype}\")\n",
        "        print(\"\\nSample sequence (first in batch):\")\n",
        "        print(\"Encoded interactions:\", sequences[0])\n",
        "        print(\"Correctness labels:\", labels[0])\n",
        "\n",
        "inspect_dataset(train_dataset, \"Training\")\n",
        "inspect_dataset(val_dataset, \"Validation\")\n",
        "inspect_dataset(test_dataset, \"Test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J42AT8iQSA98"
      },
      "source": [
        "# Transformer Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0Z-kZIbSGlm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, MultiHeadAttention, LayerNormalization, Embedding, Concatenate, Input\n",
        "\n",
        "# ================================================\n",
        "# Transformer Block with Causal Masking\n",
        "# ================================================\n",
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = Sequential([\n",
        "            Dense(ff_dim, activation=\"relu\"),\n",
        "            Dense(embed_dim)\n",
        "        ])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training, mask):\n",
        "        # Pass the mask to the attention layer.\n",
        "        attn_output = self.att(inputs, inputs, inputs, attention_mask=mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "# ================================================\n",
        "# Transformer Model for Separate Skill and Correctness Encoding\n",
        "# ================================================\n",
        "class TransformerModel(tf.keras.Model):\n",
        "    def __init__(self, num_skills, seq_len, embed_dim, num_heads, ff_dim, num_blocks, mlp_units, dropout_rate=0.1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          num_skills: Number of unique skills in the dataset.\n",
        "          seq_len: Length of the sequences.\n",
        "          embed_dim: Embedding dimension.\n",
        "          num_heads: Number of attention heads.\n",
        "          ff_dim: Feed-forward network hidden layer size.\n",
        "          num_blocks: Number of transformer blocks.\n",
        "          mlp_units: List with the number of units for each MLP Dense layer.\n",
        "          dropout_rate: Dropout rate.\n",
        "        \"\"\"\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "        # Separate embeddings for skills and correctness\n",
        "        self.skill_embedding = Embedding(num_skills, embed_dim // 2)\n",
        "        self.correctness_embedding = Embedding(2, embed_dim // 2)  # 2 possible values: 0 or 1\n",
        "\n",
        "        # Positional encoding as an Embedding layer\n",
        "        self.pos_encoding = Embedding(seq_len, embed_dim)\n",
        "\n",
        "        self.transformer_blocks = [\n",
        "            TransformerBlock(embed_dim, num_heads, ff_dim, dropout_rate)\n",
        "            for _ in range(num_blocks)\n",
        "        ]\n",
        "        self.mlp_layers = [Dense(mlp_dim, activation=\"relu\") for mlp_dim in mlp_units]\n",
        "        self.dropout = Dropout(dropout_rate)\n",
        "        self.final_layer = Dense(1)  # No activation here; we apply sigmoid later.\n",
        "\n",
        "    def causal_attention_mask(self, batch_size, seq_len):\n",
        "        \"\"\"\n",
        "        Create a boolean causal mask of shape (batch_size, seq_len, seq_len)\n",
        "        where True indicates allowed (i.e. non-masked) positions.\n",
        "        \"\"\"\n",
        "        # Create a lower-triangular matrix of ones.\n",
        "        lower_triangle = tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "        # Cast to boolean: True means allowed.\n",
        "        mask = tf.cast(lower_triangle, dtype=tf.bool)\n",
        "        # Tile for each sample in the batch.\n",
        "        mask = tf.tile(tf.expand_dims(mask, 0), [batch_size, 1, 1])\n",
        "        return mask\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          inputs: Tensor of shape (batch_size, seq_len, 2) where [:,:,0] contains skill IDs\n",
        "                 and [:,:,1] contains correctness values.\n",
        "          training: Boolean, for dropout behavior.\n",
        "        Returns:\n",
        "          predictions: Tensor of shape (batch_size, seq_len) with values in [0,1].\n",
        "        \"\"\"\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "\n",
        "        # Split the input into skill IDs and correctness values\n",
        "        skill_ids = tf.cast(inputs[:, :, 0], tf.int32)     # (batch_size, seq_len)\n",
        "        correctness = tf.cast(inputs[:, :, 1], tf.int32)   # (batch_size, seq_len)\n",
        "\n",
        "        # Create positional indices\n",
        "        positions = tf.range(start=0, limit=self.seq_len, delta=1)\n",
        "        positions = tf.expand_dims(positions, 0)           # (1, seq_len)\n",
        "        positions = tf.tile(positions, [batch_size, 1])    # (batch_size, seq_len)\n",
        "\n",
        "        # Get embeddings for skills and correctness\n",
        "        skill_emb = self.skill_embedding(skill_ids)           # (batch_size, seq_len, embed_dim//2)\n",
        "        correctness_emb = self.correctness_embedding(correctness)  # (batch_size, seq_len, embed_dim//2)\n",
        "\n",
        "        # Concatenate the skill and correctness embeddings\n",
        "        x = tf.concat([skill_emb, correctness_emb], axis=-1)  # (batch_size, seq_len, embed_dim)\n",
        "\n",
        "        # Add positional encoding\n",
        "        pos_enc = self.pos_encoding(positions)\n",
        "        x = x + pos_enc\n",
        "\n",
        "        # Create the causal mask\n",
        "        mask = self.causal_attention_mask(batch_size, self.seq_len)  # (batch_size, seq_len, seq_len)\n",
        "\n",
        "        # Pass through transformer blocks\n",
        "        for block in self.transformer_blocks:\n",
        "            x = block(x, training=training, mask=mask)\n",
        "\n",
        "        # Pass through the MLP layers\n",
        "        for layer in self.mlp_layers:\n",
        "            x = layer(x)\n",
        "            x = self.dropout(x, training=training)\n",
        "\n",
        "        x = self.final_layer(x)  # (batch_size, seq_len, 1)\n",
        "        x = tf.sigmoid(x)        # Map outputs to [0, 1]\n",
        "        return tf.squeeze(x, -1) # (batch_size, seq_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8hOxk2FpdwC"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtECeYDDpmX2"
      },
      "outputs": [],
      "source": [
        "# ================================================\n",
        "# Training, Evaluation, and Testing\n",
        "# ================================================\n",
        "@tf.function\n",
        "def train_step(model, optimizer, batch_sequences, batch_labels):\n",
        "    \"\"\"\n",
        "    Performs one training step.\n",
        "    For knowledge tracing, we predict the outcome at time t+1.\n",
        "\n",
        "    Args:\n",
        "        model: The transformer model.\n",
        "        optimizer: Optimizer instance.\n",
        "        batch_sequences: Tensor of shape (batch_size, seq_len, 2) with skill IDs and correctness.\n",
        "        batch_labels: Tensor of shape (batch_size, seq_len) with correctness values.\n",
        "    \"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(batch_sequences, training=True)\n",
        "        # Shift predictions and labels so that prediction at time t is compared with label at time t+1.\n",
        "        pred = predictions[:, :-1]\n",
        "        target = tf.cast(batch_labels[:, 1:], tf.float32)\n",
        "        loss = tf.keras.losses.binary_crossentropy(target, pred)\n",
        "        loss = tf.reduce_mean(loss)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "def evaluate_model(model, dataset):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the given dataset.\n",
        "    Returns:\n",
        "      auc: ROC-AUC score.\n",
        "      accuracy: Binary accuracy.\n",
        "    \"\"\"\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    for batch_sequences, batch_labels in dataset:\n",
        "        predictions = model(batch_sequences, training=False)\n",
        "        pred = predictions[:, :-1]\n",
        "        target = batch_labels[:, 1:]\n",
        "        all_preds.append(pred)\n",
        "        all_labels.append(target)\n",
        "    all_preds = tf.concat(all_preds, axis=0)\n",
        "    all_labels = tf.concat(all_labels, axis=0)\n",
        "    # Flatten the tensors.\n",
        "    all_preds_np = all_preds.numpy().flatten()\n",
        "    all_labels_np = all_labels.numpy().flatten()\n",
        "    try:\n",
        "        auc = roc_auc_score(all_labels_np, all_preds_np)\n",
        "    except Exception as e:\n",
        "        print(\"Error computing AUC:\", e)\n",
        "        auc = 0.0\n",
        "    y_pred_bin = (all_preds_np > 0.5).astype(int)\n",
        "    accuracy = accuracy_score(all_labels_np, y_pred_bin)\n",
        "    return auc, accuracy\n",
        "\n",
        "def train_model(model, train_dataset, val_dataset, test_dataset, epochs=50, patience=10, learning_rate=0.001):\n",
        "    \"\"\"\n",
        "    Train the Transformer model while evaluating on training, validation, and test sets.\n",
        "    Early stopping is applied based on validation AUC.\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    best_test_auc = 0.0\n",
        "    patience_counter = 0\n",
        "    best_weights = None\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "        train_loss_metric = tf.keras.metrics.Mean()\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        # Training loop\n",
        "        for batch_idx, (batch_sequences, batch_labels) in enumerate(train_dataset):\n",
        "            loss = train_step(model, optimizer, batch_sequences, batch_labels)\n",
        "            train_loss_metric.update_state(loss)\n",
        "            if (batch_idx + 1) % 50 == 0:\n",
        "                print(f\"  Batch {batch_idx+1} - Loss: {loss:.4f}\")\n",
        "\n",
        "        epoch_loss = train_loss_metric.result().numpy()\n",
        "        print(f\"Epoch {epoch+1} - Average Training Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "        # Evaluate on test set only for faster iteration\n",
        "        test_auc, test_accuracy = evaluate_model(model, test_dataset)\n",
        "        print(f\"  Test Metrics - AUC: {test_auc:.4f} | Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "        # Early stopping based on test AUC\n",
        "        if test_auc > best_test_auc:\n",
        "            best_test_auc = test_auc\n",
        "            best_weights = model.get_weights()\n",
        "            patience_counter = 0\n",
        "            print(\"  New best model found!\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"  Early stopping triggered!\")\n",
        "                break\n",
        "\n",
        "        epoch_time = time.time() - start_time\n",
        "        print(f\"Epoch {epoch+1} took {epoch_time:.2f}s\")\n",
        "\n",
        "    if best_weights is not None:\n",
        "        model.set_weights(best_weights)\n",
        "        print(f\"\\nTraining completed. Best Test AUC: {best_test_auc:.4f}\")\n",
        "\n",
        "    final_test_auc, final_test_accuracy = evaluate_model(model, test_dataset)\n",
        "    print(f\"\\nFinal Test Metrics - AUC: {final_test_auc:.4f} | Accuracy: {final_test_accuracy:.4f}\")\n",
        "    return model\n",
        "\n",
        "# ================================================\n",
        "# Main Training Call\n",
        "# ================================================\n",
        "\n",
        "model = TransformerModel(\n",
        "    num_skills=num_skills,  # Set this to the number of unique skills in your dataset\n",
        "    seq_len=10,             # Set this to your sequence length\n",
        "    embed_dim=64,\n",
        "    num_heads=4,\n",
        "    ff_dim=64,\n",
        "    num_blocks=4,\n",
        "    mlp_units=[128, 64],\n",
        "    dropout_rate=0.1\n",
        ")\n",
        "\n",
        "# Train the model with your prepared datasets\n",
        "trained_model = train_model(\n",
        "    model=model,\n",
        "    train_dataset=train_dataset,  # Your prepared TensorFlow datasets\n",
        "    val_dataset=val_dataset,      # Your prepared validation dataset\n",
        "    test_dataset=test_dataset,    # Your prepared test dataset\n",
        "    epochs=50,\n",
        "    patience=10,\n",
        "    learning_rate=0.001\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gss1iOQ8EvCe"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTOvN5C1Eu08",
        "outputId": "2292ca3e-1577-46ab-e5a2-daf19bfbdce5"
      },
      "outputs": [],
      "source": [
        "save_dir = \"/content/drive/MyDrive/DeepKT/saved_models\"\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "model_save_path = os.path.join(save_dir, \"seq60_trained_model.weights.h5\")\n",
        "trained_model.save_weights(model_save_path)\n",
        "print(f\"Model weights saved to {model_save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dgdm9_oqEG_j"
      },
      "source": [
        "# Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xGxpEMcEHmn",
        "outputId": "ee764790-adaa-491c-9a40-31b2a297e635"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# Load the model for evaluation & visualization\n",
        "# ====================================================\n",
        "# Recreate the model architecture with the same configuration.\n",
        "\n",
        "model_save_path = \"/content/drive/MyDrive/DeepKT/saved_models/seq60_trained_model.weights.h5\"\n",
        "\n",
        "loaded_model = TransformerModel(\n",
        "    num_items=2 * len(metadata['skill_to_id']),\n",
        "    seq_len=metadata['config']['seq_length'],\n",
        "    embed_dim=64,\n",
        "    num_heads=4,\n",
        "    ff_dim=64,\n",
        "    num_blocks=4,\n",
        "    mlp_units=[128, 64],\n",
        "    dropout_rate=0.1\n",
        ")\n",
        "\n",
        "# Build the model by passing a dummy input.\n",
        "dummy_input = tf.zeros((1, metadata['config']['seq_length']))\n",
        "_ = loaded_model(dummy_input, training=False)\n",
        "\n",
        "# Load the saved weights.\n",
        "loaded_model.load_weights(model_save_path)\n",
        "print(f\"Model loaded from {model_save_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD2M7d4mNF5d"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "T2gub8q2NMlS",
        "outputId": "2f85d796-2047-4390-fe2c-9c4199928a08"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "def plot_roc_curve(model, dataset):\n",
        "    \"\"\"\n",
        "    Generate and display the ROC curve for the given dataset.\n",
        "\n",
        "    This function iterates over the dataset, collects the model predictions\n",
        "    (after shifting to align with t+1) and true labels, computes the false\n",
        "    positive and true positive rates, and then plots the ROC curve along with\n",
        "    the computed AUC.\n",
        "    \"\"\"\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    for batch_sequences, batch_labels in dataset:\n",
        "        predictions = model(batch_sequences, training=False)\n",
        "        # Align predictions with labels by removing the final timestep.\n",
        "        pred = predictions[:, :-1]\n",
        "        target = batch_labels[:, 1:]\n",
        "        all_preds.append(pred)\n",
        "        all_labels.append(target)\n",
        "\n",
        "    # Concatenate predictions and labels from all batches.\n",
        "    all_preds = tf.concat(all_preds, axis=0)\n",
        "    all_labels = tf.concat(all_labels, axis=0)\n",
        "    y_scores = all_preds.numpy().flatten()\n",
        "    y_true = all_labels.numpy().flatten()\n",
        "\n",
        "    # Compute ROC curve and AUC.\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # Plot the ROC curve.\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {roc_auc:.4f})\", lw=2)\n",
        "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", lw=2)\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"Receiver Operating Characteristic (ROC)\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf  # assuming tensorflow is used as in your original code\n",
        "\n",
        "def visualize_sample_heatmap_gradient_balanced(model, dataset, bin_size=5):\n",
        "    \"\"\"\n",
        "    Visualize a single sample's performance over time as a smoothed heatmap\n",
        "    with a gradient of blue shades. Instead of specifying a sample index, this\n",
        "    function selects the sample with ground truth values closest to a 50-50\n",
        "    split of correct (1) and incorrect (0) responses.\n",
        "\n",
        "    The function:\n",
        "      1. Retrieves one batch from the dataset.\n",
        "      2. Iterates through the batch to choose the sample whose ground truth is most balanced.\n",
        "      3. Computes model predictions (assumed shape: (batch_size, seq_len)).\n",
        "      4. Aggregates predictions and ground truth values into bins (of length bin_size).\n",
        "      5. Constructs a heatmap with two rows:\n",
        "         - Row 0: Average predicted probability per bin.\n",
        "         - Row 1: Average ground truth per bin.\n",
        "\n",
        "    Args:\n",
        "      model: The trained model that outputs predictions with shape (batch_size, seq_len).\n",
        "      dataset: A tf.data.Dataset yielding (batch_sequences, batch_labels).\n",
        "      bin_size: Number of time steps to aggregate into each bin.\n",
        "    \"\"\"\n",
        "    # Retrieve one batch from the dataset.\n",
        "    for batch_sequences, batch_labels in dataset.take(1):\n",
        "        break\n",
        "\n",
        "    # Convert tensors to NumPy arrays.\n",
        "    batch_sequences_np = batch_sequences.numpy()\n",
        "    batch_labels_np = batch_labels.numpy()\n",
        "\n",
        "    # Loop to choose the balanced test vector:\n",
        "    balanced_index = None\n",
        "    min_diff = float('inf')\n",
        "    for i in range(batch_labels_np.shape[0]):\n",
        "        # Compute the average correctness for sample i.\n",
        "        avg_correct = np.mean(batch_labels_np[i])\n",
        "        # Compute the difference from the balanced ratio of 0.5.\n",
        "        diff = abs(avg_correct - 0.5)\n",
        "        if diff < min_diff:\n",
        "            min_diff = diff\n",
        "            balanced_index = i\n",
        "\n",
        "    # Use the balanced sample.\n",
        "    sample_index = balanced_index\n",
        "\n",
        "    # Select the sample sequence and corresponding ground truth.\n",
        "    sample_sequence = batch_sequences_np[sample_index:sample_index+1]\n",
        "    sample_labels = batch_labels_np[sample_index]  # shape: (seq_len,)\n",
        "\n",
        "    # Obtain model predictions. Expected shape: (1, seq_len)\n",
        "    predictions = model(sample_sequence, training=False).numpy()\n",
        "    pred_probs = predictions[0]  # shape: (seq_len,)\n",
        "\n",
        "    seq_len = len(pred_probs)\n",
        "    num_bins = int(np.ceil(seq_len / bin_size))\n",
        "    avg_pred = []\n",
        "    avg_true = []\n",
        "    for i in range(num_bins):\n",
        "        start = i * bin_size\n",
        "        end = min((i + 1) * bin_size, seq_len)\n",
        "        avg_pred.append(np.mean(pred_probs[start:end]))\n",
        "        avg_true.append(np.mean(sample_labels[start:end]))\n",
        "\n",
        "    # Stack the aggregated values into a 2D array:\n",
        "    # Row 0: Average predicted probabilities, Row 1: Average ground truth.\n",
        "    heatmap_data = np.vstack([avg_pred, avg_true])\n",
        "\n",
        "    # Plot the heatmap with a lower vertical height.\n",
        "    fig, ax = plt.subplots(figsize=(10, 2))\n",
        "    cax = ax.imshow(heatmap_data, aspect='auto', cmap='Blues', origin='upper', interpolation='nearest')\n",
        "    fig.colorbar(cax, ax=ax, label='Value')\n",
        "\n",
        "    # Set y-axis labels.\n",
        "    ax.set_yticks([0, 1])\n",
        "    ax.set_yticklabels(['Avg Predicted', 'Avg Ground Truth'])\n",
        "    # Set x-axis ticks and labels for each bin.\n",
        "    ax.set_xticks(np.arange(num_bins))\n",
        "    x_labels = [f\"{i*bin_size+1}-{min((i+1)*bin_size, seq_len)}\" for i in range(num_bins)]\n",
        "    ax.set_xticklabels(x_labels, rotation=45)\n",
        "    ax.set_xlabel(\"Time Bins\")\n",
        "    ax.set_title(\"Smoothed Heatmap (Balanced Test Vector)\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "visualize_sample_heatmap_gradient_balanced(loaded_model, test_dataset, bin_size=5)\n",
        "\n",
        "# plot_roc_curve(loaded_model, test_dataset)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
