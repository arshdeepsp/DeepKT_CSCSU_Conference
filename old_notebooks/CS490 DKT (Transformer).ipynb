{"cells":[{"cell_type":"markdown","id":"f_tj3lYhjLvV","metadata":{"id":"f_tj3lYhjLvV"},"source":["# CS490 Deep Knowledge Tracing using Transformers\n","\n","---\n","\n","Implementation in TensorFlow. Trained using Assistments 2017"]},{"cell_type":"markdown","id":"Vw-vJOuljs4c","metadata":{"id":"Vw-vJOuljs4c"},"source":["# Importing Required Modules\n","---"]},{"cell_type":"code","execution_count":null,"id":"L0vSAxRlkIoo","metadata":{"id":"L0vSAxRlkIoo"},"outputs":[],"source":["import tensorflow as tf\n","\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, MultiHeadAttention, LayerNormalization\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.metrics import AUC\n","from tensorflow.keras.regularizers import L2\n","\n","from sklearn.model_selection import train_test_split\n","\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"markdown","id":"IRLupJcvwtUC","metadata":{"id":"IRLupJcvwtUC"},"source":["Also importing dataset"]},{"cell_type":"code","execution_count":null,"id":"M7o4_anRATdv","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16505,"status":"ok","timestamp":1738891007220,"user":{"displayName":"Hongmin Li","userId":"06177026028199857211"},"user_tz":480},"id":"M7o4_anRATdv","outputId":"407b8c5f-0f79-4a0e-b2cb-8753610042ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!ls /content/drive/MyDrive/ass*"],"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"fPdomGfx_DKI","executionInfo":{"status":"ok","timestamp":1738891100204,"user_tz":480,"elapsed":115,"user":{"displayName":"Hongmin Li","userId":"06177026028199857211"}},"outputId":"3e330d46-4f37-46d0-bddb-e5271cc17493"},"id":"fPdomGfx_DKI","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/assistments_2017.csv\n"]}]},{"cell_type":"code","execution_count":null,"id":"ud4qD2OPwwGo","metadata":{"id":"ud4qD2OPwwGo","executionInfo":{"status":"ok","timestamp":1738891118048,"user_tz":480,"elapsed":14619,"user":{"displayName":"Hongmin Li","userId":"06177026028199857211"}},"colab":{"base_uri":"https://localhost:8080/","height":796},"outputId":"656208a1-e8e0-496a-9916-e15cd71d2e08","collapsed":true},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-6-0c52445ab625>:1: DtypeWarning: Columns (76,77) have mixed types. Specify dtype option on import or set low_memory=False.\n","  data = pd.read_csv('/content/drive/MyDrive/assistments_2017.csv')\n"]},{"output_type":"execute_result","data":{"text/plain":["    studentId  MiddleSchoolId InferredGender SY ASSISTments Usage   AveKnow  \\\n","0           8               2           Male            2004-2005  0.352416   \n","1           8               2           Male            2004-2005  0.352416   \n","2           8               2           Male            2004-2005  0.352416   \n","3           8               2           Male            2004-2005  0.352416   \n","4           8               2           Male            2004-2005  0.352416   \n","5           8               2           Male            2004-2005  0.352416   \n","6           8               2           Male            2004-2005  0.352416   \n","7           8               2           Male            2004-2005  0.352416   \n","8           8               2           Male            2004-2005  0.352416   \n","9           8               2           Male            2004-2005  0.352416   \n","10          8               2           Male            2004-2005  0.352416   \n","11          8               2           Male            2004-2005  0.352416   \n","12          8               2           Male            2004-2005  0.352416   \n","13          8               2           Male            2004-2005  0.352416   \n","14          8               2           Male            2004-2005  0.352416   \n","15          8               2           Male            2004-2005  0.352416   \n","16          8               2           Male            2004-2005  0.352416   \n","17          8               2           Male            2004-2005  0.352416   \n","18          8               2           Male            2004-2005  0.352416   \n","19          8               2           Male            2004-2005  0.352416   \n","\n","    AveCarelessness  AveCorrect  NumActions  AveResBored  AveResEngcon  ...  \\\n","0          0.183276    0.483902        1056     0.208389      0.679126  ...   \n","1          0.183276    0.483902        1056     0.208389      0.679126  ...   \n","2          0.183276    0.483902        1056     0.208389      0.679126  ...   \n","3          0.183276    0.483902        1056     0.208389      0.679126  ...   \n","4          0.183276    0.483902        1056     0.208389      0.679126  ...   \n","5          0.183276    0.483902        1056     0.208389      0.679126  ...   \n","6          0.183276    0.483902        1056     0.208389      0.679126  ...   \n","7          0.183276    0.483902        1056     0.208389      0.679126  ...   \n","8          0.183276    0.483902        1056     0.208389      0.679126  ...   \n","9          0.183276    0.483902        1056     0.208389      0.679126  ...   \n","10         0.183276    0.483902        1056     0.208389      0.679126  ...   \n","11         0.183276    0.483902        1056     0.208389      0.679126  ...   \n","12         0.183276    0.483902        1056     0.208389      0.679126  ...   \n","13         0.183276    0.483902        1056     0.208389      0.679126  ...   \n","14         0.183276    0.483902        1056     0.208389      0.679126  ...   \n","15         0.183276    0.483902        1056     0.208389      0.679126  ...   \n","16         0.183276    0.483902        1056     0.208389      0.679126  ...   \n","17         0.183276    0.483902        1056     0.208389      0.679126  ...   \n","18         0.183276    0.483902        1056     0.208389      0.679126  ...   \n","19         0.183276    0.483902        1056     0.208389      0.679126  ...   \n","\n","    RES_CONFUSED  RES_FRUSTRATED  RES_OFFTASK  RES_GAMING      Ln-1        Ln  \\\n","0       0.000000        0.000000     0.785585    0.000264      0.13   0.06119   \n","1       0.887452        0.000000     0.468252    0.001483   0.06119   0.21351   \n","2       0.887452        0.000000     0.468252    0.001483     0.116  0.033306   \n","3       0.000000        0.000000     0.108417    0.010665     0.116  0.033306   \n","4       0.000000        0.000000     0.108417    0.010665  0.033306  0.118386   \n","5       0.000000        0.000000     0.785585    0.002026  0.033306  0.118386   \n","6       0.000000        1.000000     0.108417    0.005952  0.033306  0.118386   \n","7       0.060808        0.000000     0.785585    0.010665     0.348  0.138588   \n","8       0.060808        0.000000     0.916914    0.012562     0.168  0.097911   \n","9       0.060808        0.000000     0.916914    0.012562     0.168  0.097911   \n","10      0.000000        0.009561     0.088541    0.006837     0.168  0.097911   \n","11      0.000000        0.009561     0.468252    0.002815  0.097911  0.301679   \n","12      0.633474        0.000000     0.785585    0.002815  0.138588  0.093798   \n","13      0.000000        0.009561     0.108417    0.006837  0.138588  0.093798   \n","14      0.633474        0.000000     0.785585    0.001483  0.093798  0.086489   \n","15      0.000000        0.009561     0.108417    0.004243  0.093798  0.086489   \n","16      0.000000        0.009561     0.149121    0.005797     0.212  0.482958   \n","17      0.060808        0.000000     0.118054    0.005797     0.031  0.022011   \n","18      0.000000        0.000000     0.108417    0.004324  0.022011  0.020825   \n","19      0.000000        0.000000     0.108417    0.004324  0.022011  0.020825   \n","\n","    MCAS Enrolled  Selective  isSTEM  \n","0     45        0          0     NaN  \n","1     45        0          0     NaN  \n","2     45        0          0     NaN  \n","3     45        0          0     NaN  \n","4     45        0          0     NaN  \n","5     45        0          0     NaN  \n","6     45        0          0     NaN  \n","7     45        0          0     NaN  \n","8     45        0          0     NaN  \n","9     45        0          0     NaN  \n","10    45        0          0     NaN  \n","11    45        0          0     NaN  \n","12    45        0          0     NaN  \n","13    45        0          0     NaN  \n","14    45        0          0     NaN  \n","15    45        0          0     NaN  \n","16    45        0          0     NaN  \n","17    45        0          0     NaN  \n","18    45        0          0     NaN  \n","19    45        0          0     NaN  \n","\n","[20 rows x 82 columns]"],"text/html":["\n","  <div id=\"df-8e33e82f-1ecc-4cf5-8210-f4f209def25c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>studentId</th>\n","      <th>MiddleSchoolId</th>\n","      <th>InferredGender</th>\n","      <th>SY ASSISTments Usage</th>\n","      <th>AveKnow</th>\n","      <th>AveCarelessness</th>\n","      <th>AveCorrect</th>\n","      <th>NumActions</th>\n","      <th>AveResBored</th>\n","      <th>AveResEngcon</th>\n","      <th>...</th>\n","      <th>RES_CONFUSED</th>\n","      <th>RES_FRUSTRATED</th>\n","      <th>RES_OFFTASK</th>\n","      <th>RES_GAMING</th>\n","      <th>Ln-1</th>\n","      <th>Ln</th>\n","      <th>MCAS</th>\n","      <th>Enrolled</th>\n","      <th>Selective</th>\n","      <th>isSTEM</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>Male</td>\n","      <td>2004-2005</td>\n","      <td>0.352416</td>\n","      <td>0.183276</td>\n","      <td>0.483902</td>\n","      <td>1056</td>\n","      <td>0.208389</td>\n","      <td>0.679126</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.785585</td>\n","      <td>0.000264</td>\n","      <td>0.13</td>\n","      <td>0.06119</td>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>Male</td>\n","      <td>2004-2005</td>\n","      <td>0.352416</td>\n","      <td>0.183276</td>\n","      <td>0.483902</td>\n","      <td>1056</td>\n","      <td>0.208389</td>\n","      <td>0.679126</td>\n","      <td>...</td>\n","      <td>0.887452</td>\n","      <td>0.000000</td>\n","      <td>0.468252</td>\n","      <td>0.001483</td>\n","      <td>0.06119</td>\n","      <td>0.21351</td>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>Male</td>\n","      <td>2004-2005</td>\n","      <td>0.352416</td>\n","      <td>0.183276</td>\n","      <td>0.483902</td>\n","      <td>1056</td>\n","      <td>0.208389</td>\n","      <td>0.679126</td>\n","      <td>...</td>\n","      <td>0.887452</td>\n","      <td>0.000000</td>\n","      <td>0.468252</td>\n","      <td>0.001483</td>\n","      <td>0.116</td>\n","      <td>0.033306</td>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>Male</td>\n","      <td>2004-2005</td>\n","      <td>0.352416</td>\n","      <td>0.183276</td>\n","      <td>0.483902</td>\n","      <td>1056</td>\n","      <td>0.208389</td>\n","      <td>0.679126</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.108417</td>\n","      <td>0.010665</td>\n","      <td>0.116</td>\n","      <td>0.033306</td>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>Male</td>\n","      <td>2004-2005</td>\n","      <td>0.352416</td>\n","      <td>0.183276</td>\n","      <td>0.483902</td>\n","      <td>1056</td>\n","      <td>0.208389</td>\n","      <td>0.679126</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.108417</td>\n","      <td>0.010665</td>\n","      <td>0.033306</td>\n","      <td>0.118386</td>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>Male</td>\n","      <td>2004-2005</td>\n","      <td>0.352416</td>\n","      <td>0.183276</td>\n","      <td>0.483902</td>\n","      <td>1056</td>\n","      <td>0.208389</td>\n","      <td>0.679126</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.785585</td>\n","      <td>0.002026</td>\n","      <td>0.033306</td>\n","      <td>0.118386</td>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>Male</td>\n","      <td>2004-2005</td>\n","      <td>0.352416</td>\n","      <td>0.183276</td>\n","      <td>0.483902</td>\n","      <td>1056</td>\n","      <td>0.208389</td>\n","      <td>0.679126</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.108417</td>\n","      <td>0.005952</td>\n","      <td>0.033306</td>\n","      <td>0.118386</td>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>Male</td>\n","      <td>2004-2005</td>\n","      <td>0.352416</td>\n","      <td>0.183276</td>\n","      <td>0.483902</td>\n","      <td>1056</td>\n","      <td>0.208389</td>\n","      <td>0.679126</td>\n","      <td>...</td>\n","      <td>0.060808</td>\n","      <td>0.000000</td>\n","      <td>0.785585</td>\n","      <td>0.010665</td>\n","      <td>0.348</td>\n","      <td>0.138588</td>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>Male</td>\n","      <td>2004-2005</td>\n","      <td>0.352416</td>\n","      <td>0.183276</td>\n","      <td>0.483902</td>\n","      <td>1056</td>\n","      <td>0.208389</td>\n","      <td>0.679126</td>\n","      <td>...</td>\n","      <td>0.060808</td>\n","      <td>0.000000</td>\n","      <td>0.916914</td>\n","      <td>0.012562</td>\n","      <td>0.168</td>\n","      <td>0.097911</td>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>Male</td>\n","      <td>2004-2005</td>\n","      <td>0.352416</td>\n","      <td>0.183276</td>\n","      <td>0.483902</td>\n","      <td>1056</td>\n","      <td>0.208389</td>\n","      <td>0.679126</td>\n","      <td>...</td>\n","      <td>0.060808</td>\n","      <td>0.000000</td>\n","      <td>0.916914</td>\n","      <td>0.012562</td>\n","      <td>0.168</td>\n","      <td>0.097911</td>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>Male</td>\n","      <td>2004-2005</td>\n","      <td>0.352416</td>\n","      <td>0.183276</td>\n","      <td>0.483902</td>\n","      <td>1056</td>\n","      <td>0.208389</td>\n","      <td>0.679126</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.009561</td>\n","      <td>0.088541</td>\n","      <td>0.006837</td>\n","      <td>0.168</td>\n","      <td>0.097911</td>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>Male</td>\n","      <td>2004-2005</td>\n","      <td>0.352416</td>\n","      <td>0.183276</td>\n","      <td>0.483902</td>\n","      <td>1056</td>\n","      <td>0.208389</td>\n","      <td>0.679126</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.009561</td>\n","      <td>0.468252</td>\n","      <td>0.002815</td>\n","      <td>0.097911</td>\n","      <td>0.301679</td>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>Male</td>\n","      <td>2004-2005</td>\n","      <td>0.352416</td>\n","      <td>0.183276</td>\n","      <td>0.483902</td>\n","      <td>1056</td>\n","      <td>0.208389</td>\n","      <td>0.679126</td>\n","      <td>...</td>\n","      <td>0.633474</td>\n","      <td>0.000000</td>\n","      <td>0.785585</td>\n","      <td>0.002815</td>\n","      <td>0.138588</td>\n","      <td>0.093798</td>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>Male</td>\n","      <td>2004-2005</td>\n","      <td>0.352416</td>\n","      <td>0.183276</td>\n","      <td>0.483902</td>\n","      <td>1056</td>\n","      <td>0.208389</td>\n","      <td>0.679126</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.009561</td>\n","      <td>0.108417</td>\n","      <td>0.006837</td>\n","      <td>0.138588</td>\n","      <td>0.093798</td>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>Male</td>\n","      <td>2004-2005</td>\n","      <td>0.352416</td>\n","      <td>0.183276</td>\n","      <td>0.483902</td>\n","      <td>1056</td>\n","      <td>0.208389</td>\n","      <td>0.679126</td>\n","      <td>...</td>\n","      <td>0.633474</td>\n","      <td>0.000000</td>\n","      <td>0.785585</td>\n","      <td>0.001483</td>\n","      <td>0.093798</td>\n","      <td>0.086489</td>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>Male</td>\n","      <td>2004-2005</td>\n","      <td>0.352416</td>\n","      <td>0.183276</td>\n","      <td>0.483902</td>\n","      <td>1056</td>\n","      <td>0.208389</td>\n","      <td>0.679126</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.009561</td>\n","      <td>0.108417</td>\n","      <td>0.004243</td>\n","      <td>0.093798</td>\n","      <td>0.086489</td>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>Male</td>\n","      <td>2004-2005</td>\n","      <td>0.352416</td>\n","      <td>0.183276</td>\n","      <td>0.483902</td>\n","      <td>1056</td>\n","      <td>0.208389</td>\n","      <td>0.679126</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.009561</td>\n","      <td>0.149121</td>\n","      <td>0.005797</td>\n","      <td>0.212</td>\n","      <td>0.482958</td>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>Male</td>\n","      <td>2004-2005</td>\n","      <td>0.352416</td>\n","      <td>0.183276</td>\n","      <td>0.483902</td>\n","      <td>1056</td>\n","      <td>0.208389</td>\n","      <td>0.679126</td>\n","      <td>...</td>\n","      <td>0.060808</td>\n","      <td>0.000000</td>\n","      <td>0.118054</td>\n","      <td>0.005797</td>\n","      <td>0.031</td>\n","      <td>0.022011</td>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>Male</td>\n","      <td>2004-2005</td>\n","      <td>0.352416</td>\n","      <td>0.183276</td>\n","      <td>0.483902</td>\n","      <td>1056</td>\n","      <td>0.208389</td>\n","      <td>0.679126</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.108417</td>\n","      <td>0.004324</td>\n","      <td>0.022011</td>\n","      <td>0.020825</td>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>Male</td>\n","      <td>2004-2005</td>\n","      <td>0.352416</td>\n","      <td>0.183276</td>\n","      <td>0.483902</td>\n","      <td>1056</td>\n","      <td>0.208389</td>\n","      <td>0.679126</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.108417</td>\n","      <td>0.004324</td>\n","      <td>0.022011</td>\n","      <td>0.020825</td>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>20 rows Ã— 82 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e33e82f-1ecc-4cf5-8210-f4f209def25c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8e33e82f-1ecc-4cf5-8210-f4f209def25c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8e33e82f-1ecc-4cf5-8210-f4f209def25c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-c6b1f6dd-5bfb-4681-b8ad-d82ce2d65c71\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c6b1f6dd-5bfb-4681-b8ad-d82ce2d65c71')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-c6b1f6dd-5bfb-4681-b8ad-d82ce2d65c71 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"data"}},"metadata":{},"execution_count":6}],"source":["data = pd.read_csv('/content/drive/MyDrive/DeepKT/assistments_2017.csv')\n","\n","data.head(20)"]},{"cell_type":"code","source":["data.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rq_U3Fg5_NR7","executionInfo":{"status":"ok","timestamp":1738891133540,"user_tz":480,"elapsed":629,"user":{"displayName":"Hongmin Li","userId":"06177026028199857211"}},"outputId":"2faac3fd-f569-4335-a6df-0891d3a271b8"},"id":"Rq_U3Fg5_NR7","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 942816 entries, 0 to 942815\n","Data columns (total 82 columns):\n"," #   Column                                  Non-Null Count   Dtype  \n","---  ------                                  --------------   -----  \n"," 0   studentId                               942816 non-null  int64  \n"," 1   MiddleSchoolId                          942816 non-null  int64  \n"," 2   InferredGender                          769160 non-null  object \n"," 3   SY ASSISTments Usage                    942816 non-null  object \n"," 4   AveKnow                                 942816 non-null  float64\n"," 5   AveCarelessness                         942816 non-null  float64\n"," 6   AveCorrect                              942816 non-null  float64\n"," 7   NumActions                              942816 non-null  int64  \n"," 8   AveResBored                             942816 non-null  float64\n"," 9   AveResEngcon                            942816 non-null  float64\n"," 10  AveResConf                              942816 non-null  float64\n"," 11  AveResFrust                             942816 non-null  float64\n"," 12  AveResOfftask                           942816 non-null  float64\n"," 13  AveResGaming                            942816 non-null  float64\n"," 14  action_num                              942816 non-null  int64  \n"," 15  skill                                   942816 non-null  object \n"," 16  problemId                               942816 non-null  int64  \n"," 17  problemType                             942816 non-null  object \n"," 18  assignmentId                            942816 non-null  int64  \n"," 19  assistmentId                            942816 non-null  int64  \n"," 20  startTime                               942816 non-null  int64  \n"," 21  endTime                                 942816 non-null  int64  \n"," 22  timeTaken                               942816 non-null  float64\n"," 23  correct                                 942816 non-null  int64  \n"," 24  original                                942816 non-null  int64  \n"," 25  hint                                    942816 non-null  int64  \n"," 26  hintCount                               942816 non-null  int64  \n"," 27  hintTotal                               942816 non-null  int64  \n"," 28  scaffold                                942816 non-null  int64  \n"," 29  bottomHint                              942816 non-null  int64  \n"," 30  attemptCount                            942816 non-null  int64  \n"," 31  frIsHelpRequest                         942816 non-null  int64  \n"," 32  frPast5HelpRequest                      942816 non-null  int64  \n"," 33  frPast8HelpRequest                      942816 non-null  int64  \n"," 34  stlHintUsed                             942816 non-null  int64  \n"," 35  past8BottomOut                          942816 non-null  int64  \n"," 36  totalFrPercentPastWrong                 942816 non-null  float64\n"," 37  totalFrPastWrongCount                   942816 non-null  int64  \n"," 38  frPast5WrongCount                       942816 non-null  int64  \n"," 39  frPast8WrongCount                       942816 non-null  int64  \n"," 40  totalFrTimeOnSkill                      942816 non-null  float64\n"," 41  timeSinceSkill                          942816 non-null  float64\n"," 42  frWorkingInSchool                       942816 non-null  int64  \n"," 43  totalFrAttempted                        942816 non-null  int64  \n"," 44  totalFrSkillOpportunities               942816 non-null  int64  \n"," 45  responseIsFillIn                        942816 non-null  int64  \n"," 46  responseIsChosen                        942816 non-null  int64  \n"," 47  endsWithScaffolding                     942816 non-null  int64  \n"," 48  endsWithAutoScaffolding                 942816 non-null  int64  \n"," 49  frTimeTakenOnScaffolding                942816 non-null  float64\n"," 50  frTotalSkillOpportunitiesScaffolding    942816 non-null  int64  \n"," 51  totalFrSkillOpportunitiesByScaffolding  942816 non-null  float64\n"," 52  frIsHelpRequestScaffolding              942816 non-null  int64  \n"," 53  timeGreater5Secprev2wrong               942816 non-null  int64  \n"," 54  sumRight                                942816 non-null  int64  \n"," 55  helpAccessUnder2Sec                     942816 non-null  int64  \n"," 56  timeGreater10SecAndNextActionRight      942816 non-null  int64  \n"," 57  consecutiveErrorsInRow                  942816 non-null  int64  \n"," 58  sumTime3SDWhen3RowRight                 942731 non-null  float64\n"," 59  sumTimePerSkill                         942816 non-null  float64\n"," 60  totalTimeByPercentCorrectForskill       942816 non-null  float64\n"," 61  Prev5count                              942816 non-null  int64  \n"," 62  timeOver80                              942816 non-null  int64  \n"," 63  manywrong                               942816 non-null  int64  \n"," 64  confidence(BORED)                       942816 non-null  float64\n"," 65  confidence(CONCENTRATING)               942816 non-null  float64\n"," 66  confidence(CONFUSED)                    942816 non-null  float64\n"," 67  confidence(FRUSTRATED)                  942816 non-null  float64\n"," 68  confidence(OFF TASK)                    942816 non-null  float64\n"," 69  confidence(GAMING)                      942816 non-null  float64\n"," 70  RES_BORED                               942816 non-null  float64\n"," 71  RES_CONCENTRATING                       942816 non-null  float64\n"," 72  RES_CONFUSED                            942816 non-null  float64\n"," 73  RES_FRUSTRATED                          942816 non-null  float64\n"," 74  RES_OFFTASK                             942816 non-null  float64\n"," 75  RES_GAMING                              942816 non-null  float64\n"," 76  Ln-1                                    942816 non-null  object \n"," 77  Ln                                      942816 non-null  object \n"," 78  MCAS                                    942816 non-null  int64  \n"," 79  Enrolled                                942816 non-null  int64  \n"," 80  Selective                               942816 non-null  int64  \n"," 81  isSTEM                                  316974 non-null  float64\n","dtypes: float64(31), int64(45), object(6)\n","memory usage: 589.8+ MB\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ue6s6h7r_f4V"},"id":"ue6s6h7r_f4V","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"r4EviCHitptR","metadata":{"id":"r4EviCHitptR"},"source":["# Defining Model\n","---"]},{"cell_type":"code","execution_count":null,"id":"qLkuDaOBtumT","metadata":{"id":"qLkuDaOBtumT"},"outputs":[],"source":["class TransformerBlock(tf.keras.layers.Layer):\n","    def __init__(self, embed_dim, num_heads, ff_dim, dropout_rate=0.1):\n","        super(TransformerBlock, self).__init__()\n","        self.attention = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","        self.ffn = tf.keras.Sequential([\n","            Dense(ff_dim, activation=\"relu\"),\n","            Dense(embed_dim),\n","        ])\n","        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = Dropout(dropout_rate)\n","        self.dropout2 = Dropout(dropout_rate)\n","\n","    def call(self, inputs, training, mask=None):\n","        attn_output = self.attention(inputs, inputs, attention_mask=mask)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(inputs + attn_output)\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        return self.layernorm2(out1 + ffn_output)\n","\n","class Transformer_DKTModel(Model):\n","    def __init__(self, num_skills, embed_dim, num_heads, ff_dim, num_transformer_blocks, dropout_rate=0.1):\n","        super(Transformer_DKTModel, self).__init__()\n","\n","        self.input_dim = 2 * num_skills\n","        self.num_skills = num_skills\n","        self.embed_dim = embed_dim\n","\n","        self.embedding = Embedding(self.input_dim, embed_dim)\n","        self.pos_encoding = self._positional_encoding(embed_dim)\n","\n","        self.transformer_blocks = [\n","            TransformerBlock(embed_dim, num_heads, ff_dim, dropout_rate)\n","            for _ in range(num_transformer_blocks)\n","        ]\n","\n","        self.dropout = Dropout(dropout_rate)\n","        self.fc = Dense(num_skills, activation=\"sigmoid\")\n","\n","    def _positional_encoding(self, d_model, max_length=5000):\n","        pos = tf.range(max_length, dtype=tf.float32)[:, tf.newaxis]\n","        i = tf.range(d_model, dtype=tf.float32)[tf.newaxis, :]\n","        angle = pos / tf.pow(10000.0, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n","\n","        sines = tf.sin(angle[:, 0::2])\n","        cosines = tf.cos(angle[:, 1::2])\n","\n","        pos_encoding = tf.concat([sines, cosines], axis=-1)\n","        pos_encoding = pos_encoding[tf.newaxis, ...]\n","\n","        return tf.cast(pos_encoding, tf.float32)\n","\n","    def _create_causal_mask(self, size):\n","        mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n","        return mask[tf.newaxis, tf.newaxis, :, :]\n","\n","    def call(self, inputs, training=False):\n","        # Get input shape using tf.shape\n","        input_shape = tf.shape(inputs)\n","        batch_size = input_shape[0]\n","        seq_len = input_shape[1]\n","\n","        # Create causal mask\n","        mask = self._create_causal_mask(seq_len)\n","\n","        # Embedding\n","        x = self.embedding(inputs)  # (batch_size, seq_len, embed_dim)\n","\n","        # Add positional encoding\n","        x = x + self.pos_encoding[:, :seq_len, :]\n","\n","        # Apply transformer blocks\n","        for transformer in self.transformer_blocks:\n","            x = transformer(x, training=training, mask=mask)\n","\n","        x = self.dropout(x, training=training)\n","        return self.fc(x)  # (batch_size, seq_len, num_skills)\n","\n","class DKTDataGenerator(tf.keras.utils.Sequence):\n","    def __init__(self, interaction_indices, next_skill_masks, batch_size=32):\n","        self.interaction_indices = interaction_indices\n","        self.next_skill_masks = next_skill_masks\n","        self.batch_size = batch_size\n","        self.indices = np.arange(len(self.interaction_indices))\n","\n","    def __len__(self):\n","        return int(np.ceil(len(self.indices) / self.batch_size))\n","\n","    def __getitem__(self, idx):\n","        start_idx = idx * self.batch_size\n","        end_idx = min((idx + 1) * self.batch_size, len(self.indices))\n","        batch_indices = self.indices[start_idx:end_idx]\n","\n","        # Ensure inputs are properly shaped (batch_size, sequence_length)\n","        batch_x = np.array([self.interaction_indices[i] for i in batch_indices])\n","        batch_y = np.array([self.next_skill_masks[i] for i in batch_indices])\n","\n","        return tf.convert_to_tensor(batch_x), tf.convert_to_tensor(batch_y)\n","\n","    def on_epoch_end(self):\n","        np.random.shuffle(self.indices)"]},{"cell_type":"markdown","id":"FzZDR-YjjMI0","metadata":{"id":"FzZDR-YjjMI0"},"source":["# Preprocess\n","---"]},{"cell_type":"code","execution_count":null,"id":"Yt96jXT8jqcK","metadata":{"id":"Yt96jXT8jqcK"},"outputs":[],"source":["def create_skill_mappings(df):\n","    skills = df['skill'].unique()\n","    skill_to_id = {skill: idx for idx, skill in enumerate(skills)}\n","    id_to_skill = {idx: skill for skill, idx in skill_to_id.items()}\n","    return skill_to_id, id_to_skill\n","\n","def create_interaction_index(row, skill_to_id):\n","    skill_id = skill_to_id[row['skill']]\n","    return 2 * skill_id + row['correct']\n","\n","def prepare_sequences(df, skill_to_id, sequence_length=50):\n","    num_skills = len(skill_to_id)\n","    sequences = []\n","    next_skill_masks = []\n","\n","    df = df.sort_values('startTime')\n","\n","    for i in range(0, len(df) - sequence_length):\n","        window = df.iloc[i:i + sequence_length+1]\n","        sequence = []\n","        next_masks = []\n","\n","        for j in range(len(window) - 1):\n","            current_interaction = create_interaction_index(window.iloc[j], skill_to_id)\n","            sequence.append(current_interaction)\n","\n","            next_skill = window.iloc[j + 1]['skill']\n","            skill_mask = np.zeros(num_skills)\n","            skill_mask[skill_to_id[next_skill]] = 1\n","            next_masks.append(skill_mask)\n","\n","        sequences.append(sequence)\n","        next_skill_masks.append(next_masks)\n","\n","    return np.array(sequences), np.array(next_skill_masks)\n","\n","def create_data_splits(df, skill_to_id, sequence_length=50, test_size=0.2, val_size=0.1):\n","    # Prepare sequences\n","    X, Y = prepare_sequences(df, skill_to_id, sequence_length)\n","\n","    # First split: separate test set\n","    X_temp, X_test, Y_temp, Y_test = train_test_split(\n","        X, Y, test_size=test_size, shuffle=False\n","    )\n","\n","    # Second split: separate validation from training\n","    val_size_adjusted = val_size / (1 - test_size)\n","    X_train, X_val, Y_train, Y_val = train_test_split(\n","        X_temp, Y_temp, test_size=val_size_adjusted, shuffle=False\n","    )\n","\n","    # Convert to TensorFlow tensors\n","    data_splits = {\n","        'X_train': tf.convert_to_tensor(X_train, dtype=tf.int32),\n","        'Y_train': tf.convert_to_tensor(Y_train, dtype=tf.int32),\n","        'X_val': tf.convert_to_tensor(X_val, dtype=tf.int32),\n","        'Y_val': tf.convert_to_tensor(Y_val, dtype=tf.int32),\n","        'X_test': tf.convert_to_tensor(X_test, dtype=tf.int32),\n","        'Y_test': tf.convert_to_tensor(Y_test, dtype=tf.int32)\n","    }\n","\n","    return data_splits\n","\n","\n","class DKTDataGenerator(tf.keras.utils.Sequence):\n","    def __init__(self, interaction_indices, next_skill_masks, batch_size=32):\n","        self.interaction_indices = interaction_indices\n","        self.next_skill_masks = next_skill_masks\n","        self.batch_size = batch_size\n","        self.indices = np.arange(len(self.interaction_indices))\n","\n","    def __len__(self):\n","        return int(np.ceil(len(self.indices) / self.batch_size))\n","\n","    def __getitem__(self, idx):\n","        start_idx = idx * self.batch_size\n","        end_idx = min((idx + 1) * self.batch_size, len(self.indices))\n","        batch_indices = self.indices[start_idx:end_idx]\n","\n","        # Ensure inputs are properly shaped (batch_size, sequence_length)\n","        batch_x = np.array([self.interaction_indices[i] for i in batch_indices])\n","        batch_y = np.array([self.next_skill_masks[i] for i in batch_indices])\n","\n","        return tf.convert_to_tensor(batch_x), tf.convert_to_tensor(batch_y)\n","\n","    def on_epoch_end(self):\n","        np.random.shuffle(self.indices)\n","\n","df = data[data['studentId'] == 8]  # Your student data\n","\n","# Create skill mappings\n","skill_to_id, id_to_skill = create_skill_mappings(df)\n","\n","# Create all data splits\n","data_splits = create_data_splits(\n","    df=df,\n","    skill_to_id=skill_to_id,\n","    sequence_length=50,\n","    test_size=0.2,\n","    val_size=0.1\n",")"]},{"cell_type":"code","source":["data_splits"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZJub9WcGCoGS","executionInfo":{"status":"ok","timestamp":1738892516429,"user_tz":480,"elapsed":16,"user":{"displayName":"Hongmin Li","userId":"06177026028199857211"}},"outputId":"fd635464-f70e-48d5-eace-7c127fc14d31"},"id":"ZJub9WcGCoGS","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'X_train': <tf.Tensor: shape=(703, 50), dtype=int32, numpy=\n"," array([[  0,   1,   2, ...,  10,  23,  13],\n","        [  1,   2,   2, ...,  23,  13,  11],\n","        [  2,   2,   3, ...,  13,  11,  10],\n","        ...,\n","        [ 95, 121,   3, ...,  11,  10,  10],\n","        [121,   3,  94, ...,  10,  10,  10],\n","        [  3,  94,  95, ...,  10,  10,  11]], dtype=int32)>,\n"," 'Y_train': <tf.Tensor: shape=(703, 50, 76), dtype=int32, numpy=\n"," array([[[1, 0, 0, ..., 0, 0, 0],\n","         [0, 1, 0, ..., 0, 0, 0],\n","         [0, 1, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        [[0, 1, 0, ..., 0, 0, 0],\n","         [0, 1, 0, ..., 0, 0, 0],\n","         [0, 1, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        [[0, 1, 0, ..., 0, 0, 0],\n","         [0, 1, 0, ..., 0, 0, 0],\n","         [0, 1, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        ...,\n"," \n","        [[0, 0, 0, ..., 0, 0, 0],\n","         [0, 1, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        [[0, 1, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        [[0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]]], dtype=int32)>,\n"," 'X_val': <tf.Tensor: shape=(101, 50), dtype=int32, numpy=\n"," array([[ 94,  95,  94, ...,  10,  11, 142],\n","        [ 95,  94,  95, ...,  11, 142, 142],\n","        [ 94,  95,  94, ..., 142, 142, 142],\n","        ...,\n","        [123,  22,  22, ..., 122, 122, 122],\n","        [ 22,  22,  22, ..., 122, 122, 123],\n","        [ 22,  22,  23, ..., 122, 123, 122]], dtype=int32)>,\n"," 'Y_val': <tf.Tensor: shape=(101, 50, 76), dtype=int32, numpy=\n"," array([[[0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        [[0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        [[0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        ...,\n"," \n","        [[0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        [[0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        [[0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]]], dtype=int32)>,\n"," 'X_test': <tf.Tensor: shape=(202, 50), dtype=int32, numpy=\n"," array([[ 22,  23,  66, ..., 123, 122, 122],\n","        [ 23,  66,  66, ..., 122, 122, 122],\n","        [ 66,  66,  67, ..., 122, 122, 122],\n","        ...,\n","        [ 71,  10,  11, ..., 138, 139,  90],\n","        [ 10,  11,  12, ..., 139,  90,  90],\n","        [ 11,  12,  12, ...,  90,  90,  90]], dtype=int32)>,\n"," 'Y_test': <tf.Tensor: shape=(202, 50, 76), dtype=int32, numpy=\n"," array([[[0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        [[0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        [[0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        ...,\n"," \n","        [[0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        [[0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        [[0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]]], dtype=int32)>}"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","id":"tijEGsPmtyGh","metadata":{"id":"tijEGsPmtyGh"},"source":["# Training Code\n","---"]},{"cell_type":"code","execution_count":null,"id":"pzne8qV7t2Dn","metadata":{"id":"pzne8qV7t2Dn"},"outputs":[],"source":["def train_model(train_generator, val_generator, num_skills, epochs=50):\n","    model = Transformer_DKTModel(\n","        num_skills=len(skill_to_id),\n","        embed_dim=128,        # Increased from 64\n","        num_heads=4,          # Reduced from 8\n","        ff_dim=256,          # Increased from 128\n","        num_transformer_blocks=3,  # Reduced from 6\n","        dropout_rate=0.2     # Increased from 0.1\n","    )\n","\n","    optimizer = tf.keras.optimizers.AdamW(\n","        learning_rate=0.001,\n","        weight_decay=0.01,\n","        clipnorm=1.0\n","    )\n","\n","    model.compile(\n","        optimizer=optimizer,\n","        loss=tf.keras.losses.BinaryCrossentropy(),\n","        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n","    )\n","\n","    callbacks = [\n","        tf.keras.callbacks.EarlyStopping(\n","            monitor='val_loss',\n","            patience=10,\n","            restore_best_weights=True,\n","            min_delta=0.001\n","        ),\n","        tf.keras.callbacks.ReduceLROnPlateau(\n","            monitor='val_loss',\n","            factor=0.5,\n","            patience=5,\n","            min_lr=0.0001,\n","            min_delta=0.001\n","        ),\n","        tf.keras.callbacks.ModelCheckpoint(\n","            'transformer_dkt_best.weights.h5',\n","            monitor='val_auc',\n","            save_weights_only=True,\n","            mode='max'\n","        )\n","    ]\n","\n","    history = model.fit(\n","        train_generator,\n","        validation_data=val_generator,\n","        epochs=epochs,\n","        callbacks=callbacks\n","    )\n","\n","    return model, history\n","\n","def execute_training(data_splits, skill_to_id, batch_size=32, epochs=50):\n","    train_generator = DKTDataGenerator(\n","        data_splits['X_train'],\n","        data_splits['Y_train'],\n","        batch_size=batch_size\n","    )\n","\n","    val_generator = DKTDataGenerator(\n","        data_splits['X_val'],\n","        data_splits['Y_val'],\n","        batch_size=batch_size\n","    )\n","\n","    model, history = train_model(\n","        train_generator,\n","        val_generator,\n","        num_skills=len(skill_to_id),\n","        epochs=epochs\n","    )\n","\n","    return model, history"]},{"cell_type":"markdown","id":"HBtkub6vt4Dy","metadata":{"id":"HBtkub6vt4Dy"},"source":["# Testing Code\n","---"]},{"cell_type":"code","source":["def evaluate_model(model, data_splits, id_to_skill):\n","    test_predictions = model.predict(data_splits['X_test'])\n","\n","    test_results = model.evaluate(\n","        data_splits['X_test'],\n","        data_splits['Y_test'],\n","        verbose=0\n","    )\n","\n","    print(\"\\nOverall Test Set Performance:\")\n","    print(f\"Loss: {test_results[0]:.4f}\")\n","    print(f\"Accuracy: {test_results[1]:.4f}\")\n","    print(f\"AUC: {test_results[2]:.4f}\")\n","\n","    return test_predictions\n","\n","def analyze_skill_performance(predictions, true_values, id_to_skill):\n","    num_skills = len(id_to_skill)\n","    skill_metrics = {}\n","\n","    for skill_id in range(num_skills):\n","        skill_name = id_to_skill[skill_id]\n","\n","        # Reshape tensors to 1D arrays\n","        skill_pred = tf.reshape(predictions[:, :, skill_id], [-1])\n","        skill_true = tf.reshape(true_values[:, :, skill_id], [-1])\n","\n","        # Calculate metrics\n","        accuracy = tf.reduce_mean(tf.keras.metrics.binary_accuracy(skill_true, skill_pred))\n","        auc = tf.keras.metrics.AUC()\n","        auc.update_state(skill_true, skill_pred)\n","\n","        skill_metrics[skill_name] = {\n","            'accuracy': float(accuracy),\n","            'auc': float(auc.result())\n","        }\n","\n","    return skill_metrics\n","\n","def analyze_sequential_predictions(predictions, true_values, id_to_skill, num_sequences=5):\n","    for seq_idx in range(min(num_sequences, predictions.shape[0])):\n","        print(f\"\\nSequence {seq_idx + 1} Analysis:\")\n","        sequence_pred = predictions[seq_idx]\n","        sequence_true = true_values[seq_idx]\n","\n","        for step in range(sequence_pred.shape[0]):\n","            pred_skill_id = int(tf.argmax(sequence_pred[step]))\n","            true_skill_id = int(tf.argmax(sequence_true[step]))\n","\n","            pred_prob = float(sequence_pred[step][pred_skill_id])\n","\n","            print(f\"\\nStep {step + 1}:\")\n","            print(f\"Predicted Skill: {id_to_skill[pred_skill_id]}\")\n","            print(f\"Actual Skill: {id_to_skill[true_skill_id]}\")\n","            print(f\"Prediction Confidence: {pred_prob:.3f}\")\n","\n","def run_model_evaluation(model, data_splits, id_to_skill):\n","    print(\"Starting model evaluation...\")\n","\n","    test_predictions = evaluate_model(model, data_splits, id_to_skill)\n","\n","    skill_metrics = analyze_skill_performance(\n","        test_predictions,\n","        data_splits['Y_test'],\n","        id_to_skill\n","    )\n","\n","    print(\"\\nPer-Skill Performance:\")\n","    for skill, metrics in skill_metrics.items():\n","        print(f\"\\nSkill: {skill}\")\n","        print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n","        print(f\"AUC: {metrics['auc']:.4f}\")\n","\n","    print(\"\\nDetailed Sequence Analysis:\")\n","    analyze_sequential_predictions(\n","        test_predictions,\n","        data_splits['Y_test'],\n","        id_to_skill\n","    )\n","\n","    return test_predictions, skill_metrics\n","\n","def execute_testing(model, data_splits, skill_to_id):\n","    id_to_skill = {v: k for k, v in skill_to_id.items()}\n","    predictions, metrics = run_model_evaluation(model, data_splits, id_to_skill)\n","    return predictions, metrics"],"metadata":{"id":"jx-uCz1wxsKm"},"id":"jx-uCz1wxsKm","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"xSAtQGEWuFY6","metadata":{"id":"xSAtQGEWuFY6"},"source":["# Run\n","---"]},{"cell_type":"code","source":["data_splits"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aN8PV-tUCVn3","executionInfo":{"status":"ok","timestamp":1738891948625,"user_tz":480,"elapsed":19,"user":{"displayName":"Hongmin Li","userId":"06177026028199857211"}},"outputId":"cecdaac5-aa05-4f78-aa18-a02377dee5d4"},"id":"aN8PV-tUCVn3","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'X_train': <tf.Tensor: shape=(703, 49), dtype=int32, numpy=\n"," array([[  0,   1,   2, ...,  21,  10,  23],\n","        [  1,   2,   2, ...,  10,  23,  13],\n","        [  2,   2,   3, ...,  23,  13,  11],\n","        ...,\n","        [ 95, 121,   3, ...,  10,  11,  10],\n","        [121,   3,  94, ...,  11,  10,  10],\n","        [  3,  94,  95, ...,  10,  10,  10]], dtype=int32)>,\n"," 'Y_train': <tf.Tensor: shape=(703, 49, 76), dtype=int32, numpy=\n"," array([[[1, 0, 0, ..., 0, 0, 0],\n","         [0, 1, 0, ..., 0, 0, 0],\n","         [0, 1, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        [[0, 1, 0, ..., 0, 0, 0],\n","         [0, 1, 0, ..., 0, 0, 0],\n","         [0, 1, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        [[0, 1, 0, ..., 0, 0, 0],\n","         [0, 1, 0, ..., 0, 0, 0],\n","         [0, 1, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        ...,\n"," \n","        [[0, 0, 0, ..., 0, 0, 0],\n","         [0, 1, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        [[0, 1, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        [[0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]]], dtype=int32)>,\n"," 'X_val': <tf.Tensor: shape=(101, 49), dtype=int32, numpy=\n"," array([[ 94,  95,  94, ...,  10,  10,  11],\n","        [ 95,  94,  95, ...,  10,  11, 142],\n","        [ 94,  95,  94, ...,  11, 142, 142],\n","        ...,\n","        [123,  22,  22, ..., 123, 122, 122],\n","        [ 22,  22,  22, ..., 122, 122, 122],\n","        [ 22,  22,  23, ..., 122, 122, 123]], dtype=int32)>,\n"," 'Y_val': <tf.Tensor: shape=(101, 49, 76), dtype=int32, numpy=\n"," array([[[0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        [[0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        [[0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        ...,\n"," \n","        [[0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        [[0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        [[0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]]], dtype=int32)>,\n"," 'X_test': <tf.Tensor: shape=(202, 49), dtype=int32, numpy=\n"," array([[ 22,  23,  66, ..., 122, 123, 122],\n","        [ 23,  66,  66, ..., 123, 122, 122],\n","        [ 66,  66,  67, ..., 122, 122, 122],\n","        ...,\n","        [ 71,  10,  11, ..., 138, 138, 139],\n","        [ 10,  11,  12, ..., 138, 139,  90],\n","        [ 11,  12,  12, ..., 139,  90,  90]], dtype=int32)>,\n"," 'Y_test': <tf.Tensor: shape=(202, 49, 76), dtype=int32, numpy=\n"," array([[[0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        [[0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        [[0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        ...,\n"," \n","        [[0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        [[0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]],\n"," \n","        [[0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0],\n","         [0, 0, 0, ..., 0, 0, 0]]], dtype=int32)>}"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","execution_count":null,"id":"-048O79-uN5v","metadata":{"id":"-048O79-uN5v","executionInfo":{"status":"ok","timestamp":1737357200434,"user_tz":480,"elapsed":452469,"user":{"displayName":"Arsh Parmar","userId":"02078315004217866348"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"65015e19-f958-4def-d980-6fe1471d8d4c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 748ms/step - accuracy: 0.0150 - auc: 0.5320 - loss: 0.3976 - val_accuracy: 0.0212 - val_auc: 0.6488 - val_loss: 0.0925 - learning_rate: 0.0010\n","Epoch 2/25\n","\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 645ms/step - accuracy: 0.0240 - auc: 0.5928 - loss: 0.0963 - val_accuracy: 0.0279 - val_auc: 0.5639 - val_loss: 0.0703 - learning_rate: 0.0010\n","Epoch 3/25\n","\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 620ms/step - accuracy: 0.0422 - auc: 0.6469 - loss: 0.0719 - val_accuracy: 0.0279 - val_auc: 0.5407 - val_loss: 0.0706 - learning_rate: 0.0010\n","Epoch 4/25\n","\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 643ms/step - accuracy: 0.0466 - auc: 0.6850 - loss: 0.0684 - val_accuracy: 0.0000e+00 - val_auc: 0.6049 - val_loss: 0.0708 - learning_rate: 0.0010\n","Epoch 5/25\n","\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 592ms/step - accuracy: 0.0534 - auc: 0.7002 - loss: 0.0674 - val_accuracy: 0.0000e+00 - val_auc: 0.6059 - val_loss: 0.0725 - learning_rate: 0.0010\n","Epoch 6/25\n","\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 638ms/step - accuracy: 0.0486 - auc: 0.7069 - loss: 0.0672 - val_accuracy: 0.0000e+00 - val_auc: 0.5943 - val_loss: 0.0730 - learning_rate: 0.0010\n","Epoch 7/25\n","\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 627ms/step - accuracy: 0.0503 - auc: 0.7123 - loss: 0.0669 - val_accuracy: 0.0000e+00 - val_auc: 0.6017 - val_loss: 0.0729 - learning_rate: 0.0010\n","Epoch 8/25\n","\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 633ms/step - accuracy: 0.0624 - auc: 0.7215 - loss: 0.0662 - val_accuracy: 0.0000e+00 - val_auc: 0.6037 - val_loss: 0.0729 - learning_rate: 5.0000e-04\n","Epoch 9/25\n","\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 605ms/step - accuracy: 0.1248 - auc: 0.7379 - loss: 0.0642 - val_accuracy: 0.1572 - val_auc: 0.6359 - val_loss: 0.0682 - learning_rate: 5.0000e-04\n","Epoch 10/25\n","\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 565ms/step - accuracy: 0.2384 - auc: 0.7741 - loss: 0.0591 - val_accuracy: 0.2443 - val_auc: 0.7040 - val_loss: 0.0621 - learning_rate: 5.0000e-04\n","Epoch 11/25\n","\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 632ms/step - accuracy: 0.3935 - auc: 0.8396 - loss: 0.0514 - val_accuracy: 0.4088 - val_auc: 0.7688 - val_loss: 0.0541 - learning_rate: 5.0000e-04\n","Epoch 12/25\n","\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 628ms/step - accuracy: 0.5184 - auc: 0.8931 - loss: 0.0446 - val_accuracy: 0.5868 - val_auc: 0.7957 - val_loss: 0.0469 - learning_rate: 5.0000e-04\n","Epoch 13/25\n","\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 658ms/step - accuracy: 0.6578 - auc: 0.9406 - loss: 0.0364 - val_accuracy: 0.6258 - val_auc: 0.8355 - val_loss: 0.0394 - learning_rate: 5.0000e-04\n","Epoch 14/25\n","\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 644ms/step - accuracy: 0.7684 - auc: 0.9695 - loss: 0.0292 - val_accuracy: 0.6702 - val_auc: 0.8480 - val_loss: 0.0351 - learning_rate: 5.0000e-04\n","Epoch 15/25\n","\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 630ms/step - accuracy: 0.8310 - auc: 0.9826 - loss: 0.0243 - val_accuracy: 0.7007 - val_auc: 0.8602 - val_loss: 0.0321 - learning_rate: 5.0000e-04\n","Epoch 16/25\n","\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 600ms/step - accuracy: 0.8766 - auc: 0.9910 - loss: 0.0202 - val_accuracy: 0.7468 - val_auc: 0.8713 - val_loss: 0.0298 - learning_rate: 5.0000e-04\n","Epoch 17/25\n","\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 632ms/step - accuracy: 0.9208 - auc: 0.9956 - loss: 0.0165 - val_accuracy: 0.7563 - val_auc: 0.8802 - val_loss: 0.0279 - learning_rate: 5.0000e-04\n","Epoch 18/25\n","\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 556ms/step - accuracy: 0.9498 - auc: 0.9972 - loss: 0.0139 - val_accuracy: 0.7585 - val_auc: 0.8905 - val_loss: 0.0260 - learning_rate: 5.0000e-04\n","Epoch 19/25\n","\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 619ms/step - accuracy: 0.9638 - auc: 0.9980 - loss: 0.0121 - val_accuracy: 0.7670 - val_auc: 0.8953 - val_loss: 0.0248 - learning_rate: 5.0000e-04\n","Epoch 20/25\n","\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 721ms/step - accuracy: 0.9787 - auc: 0.9985 - loss: 0.0103 - val_accuracy: 0.7798 - val_auc: 0.8990 - val_loss: 0.0233 - learning_rate: 5.0000e-04\n","Epoch 21/25\n","\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 643ms/step - accuracy: 0.9861 - auc: 0.9985 - loss: 0.0090 - val_accuracy: 0.7882 - val_auc: 0.9003 - val_loss: 0.0229 - learning_rate: 5.0000e-04\n","Epoch 22/25\n","\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 620ms/step - accuracy: 0.9895 - auc: 0.9986 - loss: 0.0081 - val_accuracy: 0.7943 - val_auc: 0.9039 - val_loss: 0.0220 - learning_rate: 5.0000e-04\n","Epoch 23/25\n","\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 614ms/step - accuracy: 0.9904 - auc: 0.9988 - loss: 0.0073 - val_accuracy: 0.7987 - val_auc: 0.9061 - val_loss: 0.0218 - learning_rate: 5.0000e-04\n","Epoch 24/25\n","\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 550ms/step - accuracy: 0.9928 - auc: 0.9988 - loss: 0.0066 - val_accuracy: 0.8010 - val_auc: 0.9072 - val_loss: 0.0215 - learning_rate: 5.0000e-04\n","Epoch 25/25\n","\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 612ms/step - accuracy: 0.9938 - auc: 0.9991 - loss: 0.0059 - val_accuracy: 0.8046 - val_auc: 0.9092 - val_loss: 0.0209 - learning_rate: 5.0000e-04\n","\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - accuracy: 0.7008 - auc: 0.8847 - loss: 0.0319\n"]}],"source":["# Train the model\n","model, history = execute_training(\n","    data_splits=data_splits,\n","    skill_to_id=skill_to_id,\n","    batch_size=32,\n","    epochs=25\n",")\n","\n","model.evaluate(data_splits['X_test'], data_splits['Y_test'])\n","\n","model.save('transformer_dkt_model.keras')"]}],"metadata":{"colab":{"provenance":[{"file_id":"1l9F6rFzHWyjfpKm1wJsU4CF-leKwtBm9","timestamp":1730619961150}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}